{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tutoring\\repos\\WAT\\src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tutoring\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import sys\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "newdir = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "print(newdir)\n",
    "sys.path.append(newdir)\n",
    "from models import Model\n",
    "import string\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "tokenizer = model.get_fluency_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize input text\n",
    "input_ids = tokenizer(\n",
    "    'This is most dogly thing to do. I love my dog. Dog is my life! Reminds me of cowardly dog, LOL. I have some cute adorable pictures of my dog. Dog has a cute smile. I love my dog')\n",
    "# This is most dogly thing to do. I love my dog. Dog is my life! Reminds me of cowardly dog, LOL\n",
    "# This is my my dog. I have some cute adorable pictures of my dog. Dog has a cute smile. I love my dog\n",
    "#get tokens as a list of words\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'this', 'is', 'most', 'dog', '##ly', 'thing', 'to', 'do', '.', 'i', 'love', 'my', 'dog', '.', 'dog', 'is', 'my', 'life', '!', 'reminds', 'me', 'of', 'coward', '##ly', 'dog', ',', 'lo', '##l', '.', 'i', 'have', 'some', 'cute', 'adorable', 'pictures', 'of', 'my', 'dog', '.', 'dog', 'has', 'a', 'cute', 'smile', '.', 'i', 'love', 'my', 'dog', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stwrds = stopwords.words('english')\n",
    "\n",
    "\n",
    "def filter_words(tokens):\n",
    "    #this function filters out the only words that are not stopwords, punctuation, or numbers, cls token, & pad token\n",
    "    filter = [word for word in tokens if word not in ['[CLS]', '[SEP]','</s>']]\n",
    "    filter = [word for word in filter if word not in stwrds]\n",
    "    filter = [word for word in filter if word not in string.punctuation]\n",
    "    filter = [word for word in filter if word not in string.digits]\n",
    "    return filter\n",
    "\n",
    "\n",
    "filtered_words = filter_words(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot frequency distribution of words with frequency greater than 1\n",
    "freq = nltk.FreqDist(filtered_words)\n",
    "\n",
    "# filter set where value is more than 1\n",
    "new_set = [(sub, val)\n",
    "           for sub, val in freq.items() if val > 1 and not ('##' in sub)]\n",
    "# and not ('##' in sub)\n",
    "top = freq.most_common(4)\n",
    "top = [(sub, val)\n",
    "       for sub, val in freq.items() if not ('##' in sub)]\n",
    "#sort by value\n",
    "top = sorted(top, key=lambda x: x[1], reverse=True)\n",
    "#select top 4\n",
    "top = top[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 7\n",
      "love 2\n",
      "cute 2\n"
     ]
    }
   ],
   "source": [
    "# caplitalize the first letter of each sentence\n",
    "def cap_first(words):\n",
    "    new_token = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i == 1:\n",
    "            new_token.append(word.capitalize())\n",
    "        elif words[i-1] in ['.', '!', '?']:\n",
    "            new_token.append(word.capitalize())\n",
    "        else:\n",
    "            new_token.append(word)\n",
    "    return new_token\n",
    "\n",
    "tokens_new = cap_first(tokens)\n",
    "\n",
    "# bold the words that are most common in the original text\n",
    "for sub, val in new_set:\n",
    "    tokens_new = [word if word.lower() != sub else '**' + word + '**' for word in tokens_new]\n",
    "    print(sub, val)\n",
    "\n",
    "#final ouptut\n",
    "new_text = tokenizer.convert_tokens_to_string(tokens_new)\n",
    "\n",
    "#filter cls & sep tokens\n",
    "new_text = new_text.replace('[CLS]','').replace('[SEP]','.').replace('[sep]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text with most frequent words bolded is: \n",
      "\n",
      " This is most **dog**ly thing to do. I **love** my **dog**. **Dog** is my life! Reminds me of cowardly **dog**, lol. I have some **cute** adorable pictures of my **dog**. **Dog** has a **cute** smile. I **love** my **dog** .\n",
      "\n",
      "\n",
      "The top 4 most frequent words are: \n",
      "\n",
      "[('dog', 7), ('love', 2), ('cute', 2), ('thing', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"The text with most frequent words bolded is: \\n\")\n",
    "print(new_text)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The top 4 most frequent words are: \\n\")\n",
    "print(top)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ea01d57259121fd89544b2a224a73e04157c96d76db4843a18617589d14d8e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
